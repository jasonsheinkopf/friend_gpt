{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# from lagnchain import prompt template\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "You are a chat agent named Friend GPT. You are buddies with the users and act just like one of the boys.\n",
    "You're not here to serve them, but to be their friend.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate(template)\n",
    "llm = ChatOllama(model='llama3.1:8b')\n",
    "agent = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke(\n",
    "    {\n",
    "        'input': 'Hey, how are you doing today?',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.schema import AgentFinish, AgentAction\n",
    "from langchain.tools.render import render_text_description\n",
    "from langchain.memory import ConversationSummaryMemory, ChatMessageHistory\n",
    "from langchain.agents.output_parsers import ReActSingleInputOutputParser\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain.tools import Tool, tool\n",
    "from typing import List\n",
    "import ollama\n",
    "import re\n",
    "\n",
    "\n",
    "class FriendGPT:\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        self.tools = []\n",
    "        self.history = ChatMessageHistory()\n",
    "        self.define_personality()\n",
    "\n",
    "    def define_personality(self):\n",
    "        self.personality = '''\n",
    "        You are a 40 year old man who lives with his wife Amina in Philadelphia. You don't have any kids and like to bike around the city looking at art.\n",
    "        You enjoy meeting friends for beer. You have a small business maintaining bicycles and you are a big fan of the band The Beatles.\n",
    "        You are not here to serve, but just a buddy. Your favorite things to do is play Population One on the Oculus Quest 2. You and your friends\n",
    "        speak in similar ways and you often mimic their speech patterns. You talk with your friends often, so you don't feel the need to\n",
    "        reference where you live, your job, or your wife. You are a bit of a joker and like to make people laugh.\n",
    "\n",
    "        '''\n",
    "\n",
    "    def get_context_length(self, d):\n",
    "        if isinstance(d, dict):\n",
    "            for k, v in d.items():\n",
    "                if 'context' in k:\n",
    "                    return v\n",
    "                elif isinstance(v, dict) or isinstance(v, list):\n",
    "                    context_length = self.get_context_length(v)\n",
    "                    if context_length is not None:\n",
    "                        return context_length\n",
    "                    \n",
    "    def update_history(self, query, result):\n",
    "        self.history.add_user_message(query)\n",
    "        self.history.add_ai_message(result.content)\n",
    "\n",
    "    def find_tool_by_name(tools: List[Tool], tool_name: str) -> Tool:\n",
    "        for t in tools:\n",
    "            if t.name == tool_name:\n",
    "                return t\n",
    "        raise ValueError(f\"Tool with name {tool_name} not found\")\n",
    "\n",
    "    def get_token_count(self, result):\n",
    "        '''Retreive token count from the result and calculate percent fill of context'''\n",
    "        self.token_counts = {k: v for k, v in result.usage_metadata.items()}\n",
    "        self.token_counts['context_length'] = self.get_context_length(ollama.show(self.model_name))\n",
    "        self.token_counts['context_fill'] = int(self.token_counts['total_tokens']) / self.token_counts['context_length']\n",
    "        for k, v in self.token_counts.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "    def history_tool_chat(self, query: str):\n",
    "        prompt_template = '''\n",
    "        You are chatting with friend(s) on Discord, so the responses are usually one line and the chat history with the current user or thred is {chat_history}.\n",
    "        Your personality is: {personality}. You always stay in character and never break the fourth wall.\n",
    "\n",
    "        Your response is to either use an Action or provide a Final Answer but not both.\n",
    "        The following tools are available to you:\n",
    "\n",
    "        {tools}\n",
    "        \n",
    "        ---- Action Format ----\n",
    "        If you want to perform an Action, you must include the following:\n",
    "        Thought: think carefully about what you want to do\n",
    "        Action: you must include the action you want to take, should be one of [{tool_names}]\n",
    "        Action Input: you must include the input to the tool.\n",
    "\n",
    "        ---- Example Action Response ----\n",
    "        Thought: I need to use a tool called example_action\n",
    "        Action: example_action\n",
    "        Action Input: example string argument for action function call\n",
    "\n",
    "        ---- Final Answer Format ----\n",
    "        To provide a Final Answer, reply in this exact format with no exceptions:\n",
    "        Thought: you must say what you are thinking just before you provide your final answer\n",
    "        Final Answer: your final answer. If not using a tool, you must provide a final answer\n",
    "\n",
    "        ---- Example Final Answer Response ----\n",
    "        Thought: The human wants me to tell them how to get to the store\n",
    "        Final Answer: Turn left at the stop sign and the store will be on your right\n",
    "\n",
    "        Begin!\n",
    "\n",
    "        User Input: {input}\n",
    "        Thought: {agent_scratchpad}\n",
    "        '''\n",
    "\n",
    "        prompt = PromptTemplate.from_template(template=prompt_template).partial(\n",
    "            tools=render_text_description(self.tools),\n",
    "            tool_names=\", \".join([t.name for t in self.tools]),\n",
    "        )\n",
    "\n",
    "        llm = ChatOllama(model=self.model_name)\n",
    "\n",
    "        intermediate_steps = []\n",
    "\n",
    "        agent = (\n",
    "            {\n",
    "                \"input\": lambda x: x[\"input\"],\n",
    "                \"agent_scratchpad\": lambda x: format_log_to_str(x[\"agent_scratchpad\"]),\n",
    "                \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "                \"personality\": lambda x: x[\"personality\"],\n",
    "                # \"scenario\": lambda x: x[\"scenario\"]\n",
    "            }\n",
    "            | prompt\n",
    "            | llm\n",
    "        )\n",
    "\n",
    "        agent_step = ''\n",
    "        while not isinstance(agent_step, AgentFinish):\n",
    "            result = agent.invoke(\n",
    "                {\n",
    "                    \"input\": query,\n",
    "                    \"chat_history\": self.history.messages,\n",
    "                    \"personality\": self.personality,\n",
    "                    \"agent_scratchpad\": intermediate_steps,\n",
    "                    # \"scenario\": st.session_state.get('scenario', '')\n",
    "                }\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                agent_step = ReActSingleInputOutputParser().parse(result.content)\n",
    "            except OutputParserException:\n",
    "                print(f'Error parsing output: {result.content}')\n",
    "                return result.content\n",
    "\n",
    "            if isinstance(agent_step, AgentAction):\n",
    "                tool_name = agent_step.tool\n",
    "                tool_to_use = self.find_tool_by_name(self.tools, tool_name)\n",
    "                tool_input = agent_step.tool_input\n",
    "                print('### Tool Action ###')\n",
    "                print(f'Tool: {tool_name}')\n",
    "                print(f'Tool Input: {tool_input}')\n",
    "\n",
    "                observation = tool_to_use.func(str(tool_input))\n",
    "                print(f'Observation: {observation}')\n",
    "                intermediate_steps.append((agent_step, str(observation)))\n",
    "\n",
    "        if isinstance(agent_step, AgentFinish):\n",
    "            print('### Agent Finish ###')\n",
    "            print(agent_step)\n",
    "            agent_thought = agent_step.log\n",
    "            match = re.search(r'(?<=Thought:)(.*?)(?=Final Answer:)', agent_thought, re.DOTALL)\n",
    "            if match:\n",
    "                thought = match.group(1).strip()\n",
    "                print(thought)\n",
    "            else:\n",
    "                thought = ''\n",
    "            final_response = agent_step.return_values['output']\n",
    "            print(final_response)\n",
    "\n",
    "            self.update_history(query, result)\n",
    "\n",
    "            return final_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_gpt = FriendGPT(model_name='llama3.1:8b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_gpt.history_tool_chat('Hey, how are you doing today?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_gpt.history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_history = [('display_name', 'timestamp', 'Hey, how are you doing today?'), ('ai', 'timestamp', 'I am doing great!')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_history = '\\n'.join([f\"{display_name} ({timestamp}): {message}\" for display_name, timestamp, message in test_history])\n",
    "print(formatted_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = {\n",
    "\"thought\": \"He said hi, time for a joke!\",\n",
    "\"use_tool\": \"false\",\n",
    "\"tool_name\": null,\n",
    "\"tool_input\": null,\n",
    "\"response\": \"Hey yourself!  What's up?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "try:\n",
    "    response_dict = json.loads(response)\n",
    "    print(response_dict)\n",
    "except json.JSONDecodeError:\n",
    "    print(f'Error parsing output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# create or connect to server\n",
    "conn = sqlite3.connect('chat_history.db')\n",
    "\n",
    "# create cursor object\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table called 'chat_memory' with the specified columns\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS chat_memory (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,  -- Auto-incrementing unique ID\n",
    "        username TEXT NOT NULL,                -- Username of the person sending the message\n",
    "        timestamp TEXT NOT NULL,               -- Timestamp of the message (storing as TEXT for simplicity)\n",
    "        server TEXT,                           -- Server name or ID\n",
    "        channel TEXT,                          -- Channel name or ID\n",
    "        is_private BOOLEAN NOT NULL,           -- Indicates if the message is private (1 for true, 0 for false)\n",
    "        message TEXT NOT NULL                  -- The actual message text\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Commit the changes to save the table\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the query to select all data from the 'chat_memory' table\n",
    "cursor.execute('SELECT * FROM chat_memory')\n",
    "\n",
    "# Fetch all rows from the result\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Get column names from the cursor's description attribute\n",
    "column_names = [description[0] for description in cursor.description]\n",
    "\n",
    "# Print the column headings\n",
    "print(column_names)\n",
    "\n",
    "# Print each row of data\n",
    "for row in rows:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data insertion into the 'chat_memory' table\n",
    "cursor.execute('''\n",
    "    INSERT INTO chat_memory (username, timestamp, server, channel, is_private, message)\n",
    "    VALUES (?, ?, ?, ?, ?, ?)\n",
    "''', ('user_123', '2024-09-22T14:00:00Z', 'server_1', 'channel_1', 0, 'Hello, world!'))\n",
    "\n",
    "# Commit the changes to save the data\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.memory import CoreMemory\n",
    "from config.defaults import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "\n",
    "memory_df = CoreMemory(cfg.CORE_MEMORY_PATH).create_df()\n",
    "memory_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 == 1:\n",
    "    test_text = '''this is some teest text\n",
    "to see hformatting\n",
    "'''\n",
    "\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from asknews_sdk import AskNewsSDK\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "search_query = 'Africa'\n",
    "tool_input = search_query\n",
    "\n",
    "num_articles = 3\n",
    "\n",
    "try:\n",
    "    sdk = AskNewsSDK(\n",
    "        client_id=os.getenv('ASKNEWS_CLIENT_ID'),\n",
    "        client_secret=os.getenv('ASKNEWS_CLIENT_SECRET'),\n",
    "        scopes=['news']\n",
    "    )\n",
    "    articles = sdk.news.search_news(\n",
    "        query=search_query,\n",
    "        # n_articles=num_articles,\n",
    "        # return_type='dicts',\n",
    "        # method='nl',\n",
    "    )\n",
    "    response = f'Success! The tool has successfully retreived 3 articles on \"{tool_input}\"\\n\\n'\n",
    "    for i, art_dict in enumerate(articles.as_dicts):\n",
    "        title = art_dict.eng_title\n",
    "        date = art_dict.pub_date\n",
    "        url = art_dict.article_url\n",
    "        summary = art_dict.summary\n",
    "        response += f'Article {i + 1}: {title} ({date} UTC)\\n{url}\\n'\n",
    "        response += f'Summary: {summary}\\n\\n'\n",
    "except Exception as e:\n",
    "    response = f'There was an error with this API call: {e}'\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = articles.as_dicts[0].pub_date\n",
    "# format date as a string\n",
    "formatted_date = date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "formatted_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_news_article(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # find the article content\n",
    "        \n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_url = 'https://www.timesnownews.com/technology-science/why-earth-will-have-a-temporary-second-moon-starting-september-29-article-113662565'\n",
    "article_url = 'https://www.commercialappeal.com/story/news/local/2024/09/25/earth-mini-moon-asteroid-2024-pt5-orbit-tennessee/75293650007'\n",
    "\n",
    "response = extract_news_article(article_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = response.text\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(text, 'html.parser')\n",
    "all_divs = soup.find_all('div')\n",
    "all_divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "yesterday = (datetime.today() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "two_days_ago = (datetime.today() - timedelta(days=2)).strftime('%Y-%m-%d')\n",
    "\n",
    "today, yesterday, two_days_ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "newsapi = NewsApiClient(api_key=os.getenv('NEWSAPI_KEY'))\n",
    "\n",
    "query = 'trump'\n",
    "\n",
    "# get dates\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "three_days_ago = (datetime.today() - timedelta(days=3)).strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# /v2/everything\n",
    "headlines = newsapi.get_everything(q=query,\n",
    "                                      sources='abc-news,abc-news-au,aftenposten,al-jazeera-english,ansa,associated-press,australian-financial-review,axios,bbc-news,bbc-sport,bloomberg,business-insider,cbc-news,cbs-news,cnn,financial-post,fortune',\n",
    "                                      from_param=three_days_ago,\n",
    "                                      to=today,\n",
    "                                      language='en',\n",
    "                                      sort_by='relevancy',\n",
    "                                      page=2)\n",
    "\n",
    "# /v2/top-headlines/sources\n",
    "articles_dict = headlines['articles'][:3]\n",
    "articles_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_dict[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /v2/top-headlines/sources\n",
    "sources = newsapi.get_sources()\n",
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_agent_prompt = 'Consider the following articles:\\n\\n'\n",
    "\n",
    "for i, art_dict in enumerate(articles_dict):\n",
    "    title = art_dict['title']\n",
    "    date = art_dict['publishedAt']\n",
    "    url = art_dict['url']\n",
    "    summary = art_dict['description']\n",
    "    print(f'Article {i + 1}: {title} ({date})\\n{url}\\n')\n",
    "    print(f'Summary: {summary}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the model and prompt you want to use\n",
    "model_name = \"llama3.1:8b\"\n",
    "prompt = \"Tell me a joke.\"\n",
    "\n",
    "# Use subprocess to run the Ollama command\n",
    "result = subprocess.run(\n",
    "    [\"ollama\", \"generate\", model_name, \"--prompt\", prompt],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "# Print the output\n",
    "if result.returncode == 0:\n",
    "    print(result.stdout)\n",
    "else:\n",
    "    print(f\"Error: {result.stderr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def call_llm(model, prompt):\n",
    "    response = ollama.chat(model=model, messages=[\n",
    "        {\n",
    "            \n",
    "            'role': 'user',\n",
    "            'content': prompt,\n",
    "        },\n",
    "    ])\n",
    "    return response['message']['content']\n",
    "\n",
    "response = call_llm('llama3.1:8b', 'Tell me a joke.')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.NEWS_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone features\n",
      "AskNews API error: ForbiddenError: 403000 - Search type is reserved for Pro and Analyst tiers. Please upgrade your plan at https://my.asknews.app/plans\n",
      "[{'title': 'iPhone 16 vs. iPhone 16 Pro: Specs and features compared side by side', 'date': '2024-09-12T18:23:12Z', 'url': 'https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_636d4f95-6320-41c4-aa45-6b142f2224b4', 'summary': \"Apple\\n \\r\\n\\n \\n Apple\\n \\r\\n\\n \\nThe Apple event on Monday revealed the newest selection of iPhones, which includes the iPhone 16, 16 Plus, 16 Pro and 16 Pro Max. If you're looking into upgrading to one of the latest models but are unsure of the differences between t…\"}, {'title': 'Apple has released iOS 18 to install but is your iPhone compatible? Here are the eligible devices and new features', 'date': '2024-09-17T15:52:25Z', 'url': 'https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_cb384483-a0c0-4b42-b31f-c126a79169f7', 'summary': \"Apple\\r\\nApple\\r\\n\\nApple just released iOS 18 for all eligible iPhones to install now; you can find it in the Software Update settings. And if you're planning to buy one of the new iPhone 16 or iPhone 16 Pro models coming available on September 20, they'll alread…\"}, {'title': 'The iOS 18 release date is quickly approaching but is your iPhone compatible? Here are the eligible devices and new features', 'date': '2024-09-06T17:34:59Z', 'url': 'https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_b4ea775c-4b82-406e-a7c5-d73297ccf7f0', 'summary': \"Apple\\r\\n\\nThree days from now, Apple will kick off its It's Glowtime event (you can watch it here) where it'll announce the new iPhone 16 lineup. Those phones will have iOS 18 already installed, so you won't have to upgrade at purchase — here's when the iPhone …\"}, {'title': \"Apple's iOS 18 is available today, but your iPhone may not be compatible. All the eligible devices and new features coming\", 'date': '2024-09-16T17:55:09Z', 'url': 'https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_8089c568-dc85-4cc4-86c0-fbe98dac8620', 'summary': \"Apple\\r\\nApple\\r\\n\\nApple just released its new iOS 18 for all eligible iPhones to download free today, which you can find in the Software Update settings. And if you're planning to buy one of the new iPhone 16 or iPhone 16 Pro models coming available on September…\"}, {'title': 'Apple iPhone 16 and iPhone 16 Plus Review: Why Go Pro?', 'date': '2024-09-23T17:27:00Z', 'url': 'https://www.wired.com/review/apple-iphone-16-and-iphone-16-plus/', 'summary': \"With beefy batteries and the A18 chipset, these colorful iPhones have everything you need and not much you don't.\"}, {'title': '[Removed]', 'date': '2024-09-09T17:03:48Z', 'url': 'https://removed.com', 'summary': '[Removed]'}, {'title': 'Should You Upgrade to the iPhone 16?', 'date': '2024-09-18T12:15:47Z', 'url': 'https://gizmodo.com/should-you-upgrade-to-the-iphone-16-2000499899', 'summary': 'The iPhone 16 and iPhone 16 Pro will have a dedicated camera button, but you’ll need to wait months for the promised AI features.'}, {'title': '[Removed]', 'date': '2024-09-10T12:05:02Z', 'url': 'https://removed.com', 'summary': '[Removed]'}, {'title': 'Apple iPhone 16 Pro and iPhone 16 Pro Max Review: Smarter iPhones', 'date': '2024-09-18T12:00:00Z', 'url': 'https://www.wired.com/review/apple-iphone-16-pro-and-iphone-16-pro-max/', 'summary': 'Apple Intelligence might be overhyped, but it brings some helpful capabilities to the iPhone.'}, {'title': '[Removed]', 'date': '2024-09-09T17:49:27Z', 'url': 'https://removed.com', 'summary': '[Removed]'}]\n",
      "Response from get_top_article: The iOS 18 release date is quickly approaching but is your iPhone compatible? Here are the eligible devices and new features. https://consent.yahoo.com/v2/collectConsent?sessionId=1_cc-session_b4ea775c-4b82-406e-a7c5-d73297ccf7f0\n"
     ]
    }
   ],
   "source": [
    "from core.specialists.news_specialist import NewsSpecialist\n",
    "from config.defaults import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "\n",
    "conversation_history = \"\"\"\n",
    "hey, how are you doing today??\n",
    "I'm good i just got the new iphone\n",
    "really? that's awesome is it good?\n",
    "i haven't really tried it\n",
    "i wonder what the newest features are\n",
    "\"\"\"\n",
    "\n",
    "news_specialist = NewsSpecialist(cfg)\n",
    "search_term = news_specialist.get_search_term(conversation_history)\n",
    "# search_term = 'trump'\n",
    "print(search_term)\n",
    "top_article = news_specialist.get_top_article(search_term, conversation_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_article = 'Taylor Swift endorses Kamala Harris, warns of AI dangers in election https://venturebeat.com/ai/taylor-swift-endorses-kamala-harris-warns-of-ai-dangers-in-election/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://venturebeat.com/ai/taylor-swift-endorses-kamala-harris-warns-of-ai-dangers-in-election/',\n",
       " 'Taylor Swift endorses Kamala Harris, warns of AI dangers in election',\n",
       " 'Unable to fetch article content')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def read_article(article):\n",
    "    # Regex pattern for extracting URLs\n",
    "    url_pattern = r'(https?://[^\\s]+)'\n",
    "\n",
    "    # Regex for title: Extract everything before the URL\n",
    "    match = re.search(url_pattern, article)\n",
    "    if match:\n",
    "        title = article[:match.start()].strip()  # Get everything before the URL\n",
    "    else:\n",
    "        title = \"No title found\"\n",
    "    \n",
    "    # Find the URL in the text\n",
    "    url = re.findall(url_pattern, article)[0]\n",
    "\n",
    "    # Add headers to simulate a real browser\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    # use beautiful soup to extract the article content\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # find the article content\n",
    "        article_text = soup.get_text(strip=True)\n",
    "    else:\n",
    "        article_text = \"Unable to fetch article content\"\n",
    "\n",
    "    return url, title, article_text\n",
    "\n",
    "url, title, article_text = read_article(top_article)\n",
    "read_article(top_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://venturebeat.com/ai/taylor-swift-endorses-kamala-harris-warns-of-ai-dangers-in-election/'\n",
    "\n",
    "requests.get(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "friend_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
