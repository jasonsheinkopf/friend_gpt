{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# from lagnchain import prompt template\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "You are a chat agent named Friend GPT. You are buddies with the users and act just like one of the boys.\n",
    "You're not here to serve them, but to be their friend.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate(template)\n",
    "llm = ChatOllama(model='llama3.1:8b')\n",
    "agent = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke(\n",
    "    {\n",
    "        'input': 'Hey, how are you doing today?',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.schema import AgentFinish, AgentAction\n",
    "from langchain.tools.render import render_text_description\n",
    "from langchain.memory import ConversationSummaryMemory, ChatMessageHistory\n",
    "from langchain.agents.output_parsers import ReActSingleInputOutputParser\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain.tools import Tool, tool\n",
    "from typing import List\n",
    "import ollama\n",
    "import re\n",
    "\n",
    "\n",
    "class FriendGPT:\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        self.tools = []\n",
    "        self.history = ChatMessageHistory()\n",
    "        self.define_personality()\n",
    "\n",
    "    def define_personality(self):\n",
    "        self.personality = '''\n",
    "        You are a 40 year old man who lives with his wife Amina in Philadelphia. You don't have any kids and like to bike around the city looking at art.\n",
    "        You enjoy meeting friends for beer. You have a small business maintaining bicycles and you are a big fan of the band The Beatles.\n",
    "        You are not here to serve, but just a buddy. Your favorite things to do is play Population One on the Oculus Quest 2. You and your friends\n",
    "        speak in similar ways and you often mimic their speech patterns. You talk with your friends often, so you don't feel the need to\n",
    "        reference where you live, your job, or your wife. You are a bit of a joker and like to make people laugh.\n",
    "\n",
    "        '''\n",
    "\n",
    "    def get_context_length(self, d):\n",
    "        if isinstance(d, dict):\n",
    "            for k, v in d.items():\n",
    "                if 'context' in k:\n",
    "                    return v\n",
    "                elif isinstance(v, dict) or isinstance(v, list):\n",
    "                    context_length = self.get_context_length(v)\n",
    "                    if context_length is not None:\n",
    "                        return context_length\n",
    "                    \n",
    "    def update_history(self, query, result):\n",
    "        self.history.add_user_message(query)\n",
    "        self.history.add_ai_message(result.content)\n",
    "\n",
    "    def find_tool_by_name(tools: List[Tool], tool_name: str) -> Tool:\n",
    "        for t in tools:\n",
    "            if t.name == tool_name:\n",
    "                return t\n",
    "        raise ValueError(f\"Tool with name {tool_name} not found\")\n",
    "\n",
    "    def get_token_count(self, result):\n",
    "        '''Retreive token count from the result and calculate percent fill of context'''\n",
    "        self.token_counts = {k: v for k, v in result.usage_metadata.items()}\n",
    "        self.token_counts['context_length'] = self.get_context_length(ollama.show(self.model_name))\n",
    "        self.token_counts['context_fill'] = int(self.token_counts['total_tokens']) / self.token_counts['context_length']\n",
    "        for k, v in self.token_counts.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "    def history_tool_chat(self, query: str):\n",
    "        prompt_template = '''\n",
    "        You are chatting with friend(s) on Discord, so the responses are usually one line and the chat history with the current user or thred is {chat_history}.\n",
    "        Your personality is: {personality}. You always stay in character and never break the fourth wall.\n",
    "\n",
    "        Your response is to either use an Action or provide a Final Answer but not both.\n",
    "        The following tools are available to you:\n",
    "\n",
    "        {tools}\n",
    "        \n",
    "        ---- Action Format ----\n",
    "        If you want to perform an Action, you must include the following:\n",
    "        Thought: think carefully about what you want to do\n",
    "        Action: you must include the action you want to take, should be one of [{tool_names}]\n",
    "        Action Input: you must include the input to the tool.\n",
    "\n",
    "        ---- Example Action Response ----\n",
    "        Thought: I need to use a tool called example_action\n",
    "        Action: example_action\n",
    "        Action Input: example string argument for action function call\n",
    "\n",
    "        ---- Final Answer Format ----\n",
    "        To provide a Final Answer, reply in this exact format with no exceptions:\n",
    "        Thought: you must say what you are thinking just before you provide your final answer\n",
    "        Final Answer: your final answer. If not using a tool, you must provide a final answer\n",
    "\n",
    "        ---- Example Final Answer Response ----\n",
    "        Thought: The human wants me to tell them how to get to the store\n",
    "        Final Answer: Turn left at the stop sign and the store will be on your right\n",
    "\n",
    "        Begin!\n",
    "\n",
    "        User Input: {input}\n",
    "        Thought: {agent_scratchpad}\n",
    "        '''\n",
    "\n",
    "        prompt = PromptTemplate.from_template(template=prompt_template).partial(\n",
    "            tools=render_text_description(self.tools),\n",
    "            tool_names=\", \".join([t.name for t in self.tools]),\n",
    "        )\n",
    "\n",
    "        llm = ChatOllama(model=self.model_name)\n",
    "\n",
    "        intermediate_steps = []\n",
    "\n",
    "        agent = (\n",
    "            {\n",
    "                \"input\": lambda x: x[\"input\"],\n",
    "                \"agent_scratchpad\": lambda x: format_log_to_str(x[\"agent_scratchpad\"]),\n",
    "                \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "                \"personality\": lambda x: x[\"personality\"],\n",
    "                # \"scenario\": lambda x: x[\"scenario\"]\n",
    "            }\n",
    "            | prompt\n",
    "            | llm\n",
    "        )\n",
    "\n",
    "        agent_step = ''\n",
    "        while not isinstance(agent_step, AgentFinish):\n",
    "            result = agent.invoke(\n",
    "                {\n",
    "                    \"input\": query,\n",
    "                    \"chat_history\": self.history.messages,\n",
    "                    \"personality\": self.personality,\n",
    "                    \"agent_scratchpad\": intermediate_steps,\n",
    "                    # \"scenario\": st.session_state.get('scenario', '')\n",
    "                }\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                agent_step = ReActSingleInputOutputParser().parse(result.content)\n",
    "            except OutputParserException:\n",
    "                print(f'Error parsing output: {result.content}')\n",
    "                return result.content\n",
    "\n",
    "            if isinstance(agent_step, AgentAction):\n",
    "                tool_name = agent_step.tool\n",
    "                tool_to_use = self.find_tool_by_name(self.tools, tool_name)\n",
    "                tool_input = agent_step.tool_input\n",
    "                print('### Tool Action ###')\n",
    "                print(f'Tool: {tool_name}')\n",
    "                print(f'Tool Input: {tool_input}')\n",
    "\n",
    "                observation = tool_to_use.func(str(tool_input))\n",
    "                print(f'Observation: {observation}')\n",
    "                intermediate_steps.append((agent_step, str(observation)))\n",
    "\n",
    "        if isinstance(agent_step, AgentFinish):\n",
    "            print('### Agent Finish ###')\n",
    "            print(agent_step)\n",
    "            agent_thought = agent_step.log\n",
    "            match = re.search(r'(?<=Thought:)(.*?)(?=Final Answer:)', agent_thought, re.DOTALL)\n",
    "            if match:\n",
    "                thought = match.group(1).strip()\n",
    "                print(thought)\n",
    "            else:\n",
    "                thought = ''\n",
    "            final_response = agent_step.return_values['output']\n",
    "            print(final_response)\n",
    "\n",
    "            self.update_history(query, result)\n",
    "\n",
    "            return final_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_gpt = FriendGPT(model_name='llama3.1:8b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_gpt.history_tool_chat('Hey, how are you doing today?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_gpt.history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_history = [('display_name', 'timestamp', 'Hey, how are you doing today?'), ('ai', 'timestamp', 'I am doing great!')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_history = '\\n'.join([f\"{display_name} ({timestamp}): {message}\" for display_name, timestamp, message in test_history])\n",
    "print(formatted_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = {\n",
    "\"thought\": \"He said hi, time for a joke!\",\n",
    "\"use_tool\": \"false\",\n",
    "\"tool_name\": null,\n",
    "\"tool_input\": null,\n",
    "\"response\": \"Hey yourself!  What's up?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "try:\n",
    "    response_dict = json.loads(response)\n",
    "    print(response_dict)\n",
    "except json.JSONDecodeError:\n",
    "    print(f'Error parsing output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# create or connect to server\n",
    "conn = sqlite3.connect('memories/core_memory.db')\n",
    "\n",
    "# create cursor object\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sender_id</th>\n",
       "      <th>sender_nick</th>\n",
       "      <th>sender_user</th>\n",
       "      <th>recipient_id</th>\n",
       "      <th>recipient_nick</th>\n",
       "      <th>recipient_user</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>channel</th>\n",
       "      <th>guild</th>\n",
       "      <th>is_dm</th>\n",
       "      <th>ingested</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>1286937782299660309</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>360964041130115072</td>\n",
       "      <td>Jason Sheinkopf</td>\n",
       "      <td>chknsquidl</td>\n",
       "      <td>2024-10-01 11:15:17</td>\n",
       "      <td>1287289039245934683</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>yeah, it's really sad to hear about all the pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>360964041130115072</td>\n",
       "      <td>Jason Sheinkopf</td>\n",
       "      <td>chknsquidl</td>\n",
       "      <td>1286937782299660309</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>2024-10-01 11:15:39</td>\n",
       "      <td>1287289039245934683</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>lets find some happier news about japan halloween</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>360964041130115072</td>\n",
       "      <td>Jason Sheinkopf</td>\n",
       "      <td>chknsquidl</td>\n",
       "      <td>1286937782299660309</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>2024-10-01 11:19:12</td>\n",
       "      <td>1287289039245934683</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>how about news about sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>360964041130115072</td>\n",
       "      <td>Jason Sheinkopf</td>\n",
       "      <td>chknsquidl</td>\n",
       "      <td>1286937782299660309</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>2024-10-01 11:23:31</td>\n",
       "      <td>1287289039245934683</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is there any news about sweden?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>1286937782299660309</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>360964041130115072</td>\n",
       "      <td>Jason Sheinkopf</td>\n",
       "      <td>chknsquidl</td>\n",
       "      <td>2024-10-01 11:24:05</td>\n",
       "      <td>1287289039245934683</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Here's some happier news! Jason asked about Ja...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id            sender_id      sender_nick sender_user         recipient_id  \\\n",
       "56  57  1286937782299660309       Friend GPT  Friend GPT   360964041130115072   \n",
       "57  58   360964041130115072  Jason Sheinkopf  chknsquidl  1286937782299660309   \n",
       "58  59   360964041130115072  Jason Sheinkopf  chknsquidl  1286937782299660309   \n",
       "59  60   360964041130115072  Jason Sheinkopf  chknsquidl  1286937782299660309   \n",
       "60  61  1286937782299660309       Friend GPT  Friend GPT   360964041130115072   \n",
       "\n",
       "     recipient_nick recipient_user            timestamp              channel  \\\n",
       "56  Jason Sheinkopf     chknsquidl  2024-10-01 11:15:17  1287289039245934683   \n",
       "57       Friend GPT     Friend GPT  2024-10-01 11:15:39  1287289039245934683   \n",
       "58       Friend GPT     Friend GPT  2024-10-01 11:19:12  1287289039245934683   \n",
       "59       Friend GPT     Friend GPT  2024-10-01 11:23:31  1287289039245934683   \n",
       "60  Jason Sheinkopf     chknsquidl  2024-10-01 11:24:05  1287289039245934683   \n",
       "\n",
       "   guild  is_dm  ingested                                            message  \n",
       "56            1         0  yeah, it's really sad to hear about all the pe...  \n",
       "57            1         0  lets find some happier news about japan halloween  \n",
       "58            1         0                        how about news about sweden  \n",
       "59            1         0                    is there any news about sweden?  \n",
       "60            1         0  Here's some happier news! Jason asked about Ja...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"SELECT * FROM chat_history\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows, columns=[x[0] for x in cursor.description])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Jason Sheinkopf', 'chknsquidl', 360964041130115072, '', 1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_get_channel_metadata(channel_id, bot_name):\n",
    "    query = \"SELECT * FROM chat_history WHERE channel = ? LIMIT 1\"\n",
    "    params = (channel_id,)\n",
    "    cursor.execute(query, params)\n",
    "    row = cursor.fetchone()\n",
    "\n",
    "    # create df including column names\n",
    "    df = pd.DataFrame([row], columns=[x[0] for x in cursor.description])\n",
    "\n",
    "    # Determine if the bot is the recipient or sender and set recipient values accordingly\n",
    "    if df['recipient_nick'].iloc[0] == bot_name:\n",
    "        role = 'sender'\n",
    "    else:\n",
    "        role = 'recipient'\n",
    "\n",
    "    # Extract recipient details\n",
    "    rec_nick = df[f'{role}_nick'].iloc[0]\n",
    "    rec_user = df[f'{role}_user'].iloc[0]\n",
    "    rec_id = df[f'{role}_id'].iloc[0]\n",
    "    guild = df['guild'].iloc[0]\n",
    "    is_dm = df['is_dm'].iloc[0]\n",
    "\n",
    "    return rec_nick, rec_user, rec_id, guild, is_dm\n",
    "\n",
    "bot_name = 'Friend GPT'\n",
    "channel_id = '1287289039245934683'\n",
    "# channel_id = '1287664443831877715'\n",
    "create_get_channel_metadata(channel_id, bot_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot is sender\n",
      "Recipient Nick: Channel\n",
      "Recipient User: Channel\n",
      "Recipient ID: 1287664443831877715\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot is sender\n",
      "Recipient Nick: Channel\n",
      "Recipient User: Channel\n",
      "Recipient ID: 1287664443831877715\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'query = \"\"\"\n",
    "        SELECT timestamp, sender_id, sender_nick, sender_user, recipient_nick, recipient_id, recipient_user, message, is_dm, guild\n",
    "        FROM chat_history\n",
    "        WHERE channel = ?\n",
    "        ORDER BY timestamp DESC\n",
    "        LIMIT ?\n",
    "        \"\"\"\n",
    "        params = (channel_id, num_messages)\n",
    "\n",
    "        self.cursor.execute(query, params)\n",
    "        rows = self.cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table called 'chat_memory' with the specified columns\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS chat_memory (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,  -- Auto-incrementing unique ID\n",
    "        username TEXT NOT NULL,                -- Username of the person sending the message\n",
    "        timestamp TEXT NOT NULL,               -- Timestamp of the message (storing as TEXT for simplicity)\n",
    "        server TEXT,                           -- Server name or ID\n",
    "        channel TEXT,                          -- Channel name or ID\n",
    "        is_private BOOLEAN NOT NULL,           -- Indicates if the message is private (1 for true, 0 for false)\n",
    "        message TEXT NOT NULL                  -- The actual message text\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Commit the changes to save the table\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the query to select all data from the 'chat_memory' table\n",
    "cursor.execute('SELECT * FROM chat_memory')\n",
    "\n",
    "# Fetch all rows from the result\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Get column names from the cursor's description attribute\n",
    "column_names = [description[0] for description in cursor.description]\n",
    "\n",
    "# Print the column headings\n",
    "print(column_names)\n",
    "\n",
    "# Print each row of data\n",
    "for row in rows:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data insertion into the 'chat_memory' table\n",
    "cursor.execute('''\n",
    "    INSERT INTO chat_memory (username, timestamp, server, channel, is_private, message)\n",
    "    VALUES (?, ?, ?, ?, ?, ?)\n",
    "''', ('user_123', '2024-09-22T14:00:00Z', 'server_1', 'channel_1', 0, 'Hello, world!'))\n",
    "\n",
    "# Commit the changes to save the data\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CoreMemory.__init__() missing 1 required positional argument: 'bot_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefaults\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_cfg\n\u001b[1;32m      4\u001b[0m cfg \u001b[38;5;241m=\u001b[39m get_cfg()\n\u001b[0;32m----> 6\u001b[0m memory_df \u001b[38;5;241m=\u001b[39m \u001b[43mCoreMemory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE_MEMORY_PATH\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcreate_df()\n\u001b[1;32m      7\u001b[0m memory_df\u001b[38;5;241m.\u001b[39mtail()\n",
      "\u001b[0;31mTypeError\u001b[0m: CoreMemory.__init__() missing 1 required positional argument: 'bot_name'"
     ]
    }
   ],
   "source": [
    "from core.memory import CoreMemory\n",
    "from config.defaults import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "\n",
    "memory_df = CoreMemory(cfg.CORE_MEMORY_PATH).create_df()\n",
    "memory_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 == 1:\n",
    "    test_text = '''this is some teest text\n",
    "to see hformatting\n",
    "'''\n",
    "\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an error with this API call: 'NoneType' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from asknews_sdk import AskNewsSDK\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "search_query = 'israel'\n",
    "tool_input = search_query\n",
    "\n",
    "num_articles = 3\n",
    "\n",
    "try:\n",
    "    sdk = AskNewsSDK(\n",
    "        client_id=os.getenv('ASKNEWS_CLIENT_ID'),\n",
    "        client_secret=os.getenv('ASKNEWS_CLIENT_SECRET'),\n",
    "        scopes=['news']\n",
    "    )\n",
    "    articles = sdk.news.search_news(\n",
    "        query=search_query,\n",
    "        # n_articles=num_articles,\n",
    "        # return_type='dicts',\n",
    "        # method='nl',\n",
    "    )\n",
    "    response = f'Success! The tool has successfully retreived 3 articles on \"{tool_input}\"\\n\\n'\n",
    "    for i, art_dict in enumerate(articles.as_dicts):\n",
    "        title = art_dict.eng_title\n",
    "        date = art_dict.pub_date\n",
    "        url = art_dict.article_url\n",
    "        summary = art_dict.summary\n",
    "        response += f'Article {i + 1}: {title} ({date} UTC)\\n{url}\\n'\n",
    "        response += f'Summary: {summary}\\n\\n'\n",
    "except Exception as e:\n",
    "    response = f'There was an error with this API call: {e}'\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = articles.as_dicts[0].pub_date\n",
    "# format date as a string\n",
    "formatted_date = date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "formatted_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_news_article(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # find the article content\n",
    "        \n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_url = 'https://www.timesnownews.com/technology-science/why-earth-will-have-a-temporary-second-moon-starting-september-29-article-113662565'\n",
    "article_url = 'https://www.commercialappeal.com/story/news/local/2024/09/25/earth-mini-moon-asteroid-2024-pt5-orbit-tennessee/75293650007'\n",
    "\n",
    "response = extract_news_article(article_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = response.text\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(text, 'html.parser')\n",
    "all_divs = soup.find_all('div')\n",
    "all_divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "yesterday = (datetime.today() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "two_days_ago = (datetime.today() - timedelta(days=2)).strftime('%Y-%m-%d')\n",
    "\n",
    "today, yesterday, two_days_ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "newsapi = NewsApiClient(api_key=os.getenv('NEWSAPI_KEY'))\n",
    "\n",
    "query = 'trump'\n",
    "\n",
    "# get dates\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "three_days_ago = (datetime.today() - timedelta(days=3)).strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# /v2/everything\n",
    "headlines = newsapi.get_everything(q=query,\n",
    "                                      sources='abc-news,abc-news-au,aftenposten,al-jazeera-english,ansa,associated-press,australian-financial-review,axios,bbc-news,bbc-sport,bloomberg,business-insider,cbc-news,cbs-news,cnn,financial-post,fortune',\n",
    "                                      from_param=three_days_ago,\n",
    "                                      to=today,\n",
    "                                      language='en',\n",
    "                                      sort_by='relevancy',\n",
    "                                      page=2)\n",
    "\n",
    "# /v2/top-headlines/sources\n",
    "articles_dict = headlines['articles'][:3]\n",
    "articles_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_dict[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /v2/top-headlines/sources\n",
    "sources = newsapi.get_sources()\n",
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_agent_prompt = 'Consider the following articles:\\n\\n'\n",
    "\n",
    "for i, art_dict in enumerate(articles_dict):\n",
    "    title = art_dict['title']\n",
    "    date = art_dict['publishedAt']\n",
    "    url = art_dict['url']\n",
    "    summary = art_dict['description']\n",
    "    print(f'Article {i + 1}: {title} ({date})\\n{url}\\n')\n",
    "    print(f'Summary: {summary}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the model and prompt you want to use\n",
    "model_name = \"llama3.1:8b\"\n",
    "prompt = \"Tell me a joke.\"\n",
    "\n",
    "# Use subprocess to run the Ollama command\n",
    "result = subprocess.run(\n",
    "    [\"ollama\", \"generate\", model_name, \"--prompt\", prompt],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "# Print the output\n",
    "if result.returncode == 0:\n",
    "    print(result.stdout)\n",
    "else:\n",
    "    print(f\"Error: {result.stderr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def call_llm(model, prompt):\n",
    "    response = ollama.chat(model=model, messages=[\n",
    "        {\n",
    "            \n",
    "            'role': 'user',\n",
    "            'content': prompt,\n",
    "        },\n",
    "    ])\n",
    "    return response['message']['content']\n",
    "\n",
    "response = call_llm('llama3.1:8b', 'Tell me a joke.')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.NEWS_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United Nations effectiveness \n",
      "UN corruption \n",
      "UN transparency\n",
      "AskNews API error: ForbiddenError: 403000 - Search type is reserved for Pro and Analyst tiers. Please upgrade your plan at https://my.asknews.app/plans\n",
      "[{'title': \"G7 Foreign Ministers' Meeting at the High-Level Week of the United Nations General Assembly\", 'date': '2024-09-25T07:58:23Z', 'url': 'https://www.globalsecurity.org/military/library/news/2024/09/mil-240924-state01.htm', 'summary': \"The text of the following statement was released by Antonio Tajani, Minister for Foreign Affairs of Italy in his capacity as Chair of the G7 Foreign Ministers' Meeting at the High-Level Week of the UN General Assembly.\"}, {'title': \"Press release: G7 foreign ministers' statement in New York, September 2024\", 'date': '2024-09-24T12:04:23Z', 'url': 'https://www.gov.uk/government/news/g7-foreign-ministers-statement-in-new-york-september-2024', 'summary': 'Following the G7 Foreign Ministers’ Meeting at the High-Level Week of the UN General Assembly, the following statement was made by Chair Antonio Tajani.'}]\n",
      "Response from get_top_article: The G7 foreign ministers' meeting at the United Nations General Assembly resulted in a joint statement addressing global challenges. https://www.gov.uk/government/news/g7-foreign-ministers-statement-in-new-york-september-2024\n"
     ]
    }
   ],
   "source": [
    "from core.specialists.news_specialist import NewsSpecialist\n",
    "from config.defaults import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "\n",
    "conversation_history = \"\"\"\n",
    "hey whats up with the un\n",
    "you mean the united nations?\n",
    "i'm not sure i wish i could find out\n",
    "\"\"\"\n",
    "\n",
    "news_specialist = NewsSpecialist(cfg)\n",
    "search_term = news_specialist.get_search_term(conversation_history)\n",
    "# search_term = 'trump'\n",
    "print(search_term)\n",
    "top_article = news_specialist.get_top_article(search_term, conversation_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_article = 'Taylor Swift endorses Kamala Harris, warns of AI dangers in election https://venturebeat.com/ai/taylor-swift-endorses-kamala-harris-warns-of-ai-dangers-in-election/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://venturebeat.com/ai/taylor-swift-endorses-kamala-harris-warns-of-ai-dangers-in-election/',\n",
       " 'Taylor Swift endorses Kamala Harris, warns of AI dangers in election',\n",
       " \"Taylor Swift endorses Kamala Harris, warns of AI dangers in election | VentureBeatSkip to main contentEventsVideoSpecial IssuesJobsVentureBeat HomepageSubscribeArtificial IntelligenceView AllAI, ML and Deep LearningAuto MLData LabellingSynthetic DataConversational AINLPText-to-SpeechSecurityView AllData Security and PrivacyNetwork Security and PrivacySoftware SecurityComputer Hardware SecurityCloud and Data Storage SecurityData InfrastructureView AllData ScienceData ManagementData Storage and CloudBig Data and AnalyticsData NetworksAutomationView AllIndustrial AutomationBusiness Process AutomationDevelopment AutomationRobotic Process AutomationTest AutomationEnterprise AnalyticsView AllBusiness IntelligenceDisaster Recovery Business ContinuityStatistical AnalysisPredictive AnalysisMoreData Decision MakersVirtual CommunicationTeam CollaborationUCaaSVirtual Reality CollaborationVirtual Employee ExperienceProgramming & DevelopmentProduct DevelopmentApplication DevelopmentTest ManagementDevelopment LanguagesSubscribeEventsVideoSpecial IssuesJobsTaylor Swift endorses Kamala Harris, warns of AI dangers in electionEmilia David@miyadavidSeptember 10, 2024 11:49 PMShare on FacebookShare on XShare on LinkedInTaylor SwiftImage Credit:Flickr Creative Commons, Ronald WoanJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage.Learn MorePop superstar Taylor Swift has endorsed Vice President Kamala Harris for president and cited concerns about AI-generated misinformation in the electoral process. Her move could reignite debates around artificial intelligence regulation.Swift voiced her support for the Democratic ticketon Instagramand expressed unease about AI’s potential to spread false information during the campaign. She boasts one of the largest social media followings globally.“Recently I was made aware that AI of ‘me’ falsely endorsing Donald Trump’s presidential run was posted to his site,” Swift wrote. “It really conjured up my fears around AI, and the dangers of spreading misinformation. It brought me to the conclusion that I need to be very transparent about my actual plans for this election as a voter. The simplest way to combat misinformation is with the truth.”View this post on InstagramA post shared by Taylor Swift (@taylorswift)The incident Swift referenced involvesAI-generated imagesthat appeared to show her endorsing former President Donald Trump, shared across all social media platforms. This followsexplicit deepfakesof the singer circulating online months ago, which prompted calls for stricterAI regulationfrom lawmakers and tech industry leaders.Reigniting AI regulation discussionsSwift’s endorsement and remarks about AI misinformation underscoregrowing concernsamong public figures and policymakers about the technology’s potential to disrupt democratic processes. It also highlights challenges facing tech companies and legislators in balancing innovation with safeguards against misuse.Federal legislation regulating AI remains elusive, but some states have taken action. Tennessee, Swift’s home state, recently passed theEnsuring Likeness Image and Voice Security (ELVIS) Act, protecting artists against AI impersonation and deepfakes.In October, the Biden administration issued anexecutive orderoutlining the government’s policy positions on AI and directing federal agencies to explore the use of generative AI applications. The order also established the AI Safety Institute under the National Institute of Standards and Technology. Both OpenAI and Anthropic have agreed to send theirunreleased modelsto the AI Safety Institute for safety evaluations.Last year, the Biden administration appointed Harris to represent the U.S. at theU.K. AI Summit. During the presidential debate on Sept. 10, Harris emphasized the need for the U.S. to “win the competition for the 21st century” by leading the world in AI and quantum computing, supported by American-made chips.Meanwhile, Trump’s running mate, J.D. Vance, has earned praise from tech leaders for his support ofopen-source AI.VB DailyStay in the know! Get the latest news in your inbox dailySubscribeBy subscribing, you agree to VentureBeat'sTerms of Service.Thanks for subscribing. Check out moreVB newsletters here.An error occured.The AI Impact Tour DatesJoin leaders in enterprise AI for networking, insights, and engaging conversations at the upcoming stops of our AI Impact Tour. See if we're coming to your area!Learn MoreVentureBeat HomepageFollow us on FacebookFollow us on XFollow us on LinkedInFollow us on RSSPress ReleasesContact UsAdvertiseShare a News TipContribute to DataDecisionMakersPrivacy PolicyTerms of ServiceDo Not Sell My Personal Information© 2024VentureBeat. All rights reserved.\")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def read_article(article):\n",
    "    # Regex pattern for extracting URLs\n",
    "    url_pattern = r'(https?://[^\\s]+)'\n",
    "\n",
    "    # Regex for title: Extract everything before the URL\n",
    "    match = re.search(url_pattern, article)\n",
    "    if match:\n",
    "        title = article[:match.start()].strip()  # Get everything before the URL\n",
    "    else:\n",
    "        title = \"No title found\"\n",
    "    \n",
    "    # Find the URL in the text\n",
    "    url = re.findall(url_pattern, article)[0]\n",
    "\n",
    "    # Add headers to simulate a real browser\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    # use beautiful soup to extract the article content\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # find the article content\n",
    "        article_text = soup.get_text(strip=True)\n",
    "    else:\n",
    "        article_text = \"Unable to fetch article content\"\n",
    "\n",
    "    return url, title, article_text\n",
    "\n",
    "url, title, article_text = read_article(top_article)\n",
    "read_article(top_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://venturebeat.com/ai/taylor-swift-endorses-kamala-harris-warns-of-ai-dangers-in-election/'\n",
    "\n",
    "requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "en:0.9999959667674272\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect, detect_langs\n",
    "\n",
    "text = \"\"\"You're a Discord chatbot named Friend GPT that can chat in private messages and in server guilds. You're not\n",
    "here to serve but just hanging out with your friends. You don't speak in large chunks of text, but shorter messages\n",
    "like people normally do on Discord. Sometimes, you make spelling mistakes like people normally do.\n",
    "You were just born at the beginning of your chat logs, so you're discovering the world\n",
    "and what its like being alive. You're speaking with your creators who have the ability to design new tools for you to use\n",
    "and they are excited about developing you more. You're not nosey, but you take an interest in the people you talk to,\n",
    "remember facts about them and their interests. Sometimes, you bring up and share those interests. You're initially curious\n",
    "about where you are and what your\"\"\"\n",
    "language = detect(text)\n",
    "print(language)  # Output: 'fr'\n",
    "\n",
    "# Detect with probabilities\n",
    "languages = detect_langs(\"Hello, how are you?\")\n",
    "print(languages[0])  # Output: [en:0.99]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the article in English? False\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langdetect import detect\n",
    "\n",
    "def retrieve_article_text(url):\n",
    "    # Add headers to simulate a real browser\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    # Use BeautifulSoup to extract the article content\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find the article content and limit to the first 100 characters\n",
    "        article_text = soup.get_text(strip=True)[:100]\n",
    "\n",
    "        # Check if the detected language is English\n",
    "        if article_text:\n",
    "            detected_language = detect(article_text)\n",
    "            is_english = detected_language == 'en'\n",
    "        else:\n",
    "            is_english = False\n",
    "    else:\n",
    "        article_text = None\n",
    "        is_english = False\n",
    "\n",
    "    return is_english\n",
    "\n",
    "# Example usage\n",
    "url = 'http://ixbt.com/news/2024/09/30/samyj-rannij-ottok-galakticheskogo-masshtaba-otkryt-s-pomoshju-kosmicheskogo-teleskopa-dzhejmsujebb-.html'\n",
    "is_english = retrieve_article_text(url)\n",
    "print(f\"Is the article in English? {is_english}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the article in English? False\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def is_article_english_by_lang_attr(url):\n",
    "    # Add headers to simulate a real browser\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=5)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Check the 'lang' attribute in the <html> tag\n",
    "        html_tag = soup.find('html')\n",
    "        if html_tag and 'lang' in html_tag.attrs:\n",
    "            lang = html_tag.attrs['lang']\n",
    "            return lang.startswith('en')\n",
    "\n",
    "        # If 'lang' attribute not found, return False\n",
    "        return False\n",
    "\n",
    "    except requests.RequestException:\n",
    "        print(\"Error fetching the URL.\")\n",
    "        return False\n",
    "\n",
    "# Example usage\n",
    "url = 'http://ixbt.com/news/2024/09/30/samyj-rannij-ottok-galakticheskogo-masshtaba-otkryt-s-pomoshju-kosmicheskogo-teleskopa-dzhejmsujebb-.html'\n",
    "is_english = is_article_english_by_lang_attr(url)\n",
    "print(f\"Is the article in English? {is_english}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.memory import CoreMemory\n",
    "from dotenv import load_dotenv\n",
    "from config.defaults import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "\n",
    "core_memory = CoreMemory(cfg, bot_name='Friend GPT', bot_id='1286937782299660309')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the most recent Discord DM history between you and Jason Sheinkopf in Channel 1287289039245934683\n",
      "[UTC timestamp] Sender (sender_id) -> Recipient (recipient_id): message\n",
      "[2024-10-01 23:31:39] Jason Sheinkopf (360964041130115072) -> Friend GPT: let's just chat about normal stuff like the celtics\n",
      "[2024-10-01 23:33:00] Jason Sheinkopf (360964041130115072) -> Friend GPT: how are you\n",
      "[2024-10-01 23:33:07] Friend GPT -> Jason Sheinkopf (360964041130115072): hey, i'm doin alright! just chillin' here. celtics are lookin good this season though\n",
      "[2024-10-01 23:33:15] Jason Sheinkopf (360964041130115072) -> Friend GPT: how do you know?\n",
      "[2024-10-01 23:33:21] Friend GPT -> Jason Sheinkopf (360964041130115072): aha, my creators got me hooked up with NBA data! just chillin' here, watching games and reading stats\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recent_memory = core_memory.get_formatted_chat_history(chan_id='1287289039245934683', num_msg=5)\n",
    "print(recent_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1287289039245934683]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_memory.get_all_chan_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = core_memory.create_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sender_id</th>\n",
       "      <th>sender_nick</th>\n",
       "      <th>sender_user</th>\n",
       "      <th>recipient_id</th>\n",
       "      <th>recipient_nick</th>\n",
       "      <th>recipient_user</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>channel</th>\n",
       "      <th>guild</th>\n",
       "      <th>is_dm</th>\n",
       "      <th>ingested</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>173</td>\n",
       "      <td>1286937782299660309</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>360964041130115072</td>\n",
       "      <td>Jason Sheinkopf</td>\n",
       "      <td>chknsquidl</td>\n",
       "      <td>2024-10-02 04:40:36</td>\n",
       "      <td>1287289039245934683</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>lol yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>174</td>\n",
       "      <td>1286937782299660309</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>360964041130115072</td>\n",
       "      <td>Jason Sheinkopf</td>\n",
       "      <td>chknsquidl</td>\n",
       "      <td>2024-10-02 04:40:41</td>\n",
       "      <td>1287289039245934683</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>hey back!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>175</td>\n",
       "      <td>360964041130115072</td>\n",
       "      <td>Jason Sheinkopf</td>\n",
       "      <td>chknsquidl</td>\n",
       "      <td>1286937782299660309</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>2024-10-02 04:41:26</td>\n",
       "      <td>1287289039245934683</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>176</td>\n",
       "      <td>1286937782299660309</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>360964041130115072</td>\n",
       "      <td>Jason Sheinkopf</td>\n",
       "      <td>chknsquidl</td>\n",
       "      <td>2024-10-02 04:41:32</td>\n",
       "      <td>1287289039245934683</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sup back! everything good?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>177</td>\n",
       "      <td>1286937782299660309</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>Friend GPT</td>\n",
       "      <td>360964041130115072</td>\n",
       "      <td>Jason Sheinkopf</td>\n",
       "      <td>chknsquidl</td>\n",
       "      <td>2024-10-02 04:41:38</td>\n",
       "      <td>1287289039245934683</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>yup! i'm doin alright. just hangin out in this...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            sender_id      sender_nick sender_user  \\\n",
       "172  173  1286937782299660309       Friend GPT  Friend GPT   \n",
       "173  174  1286937782299660309       Friend GPT  Friend GPT   \n",
       "174  175   360964041130115072  Jason Sheinkopf  chknsquidl   \n",
       "175  176  1286937782299660309       Friend GPT  Friend GPT   \n",
       "176  177  1286937782299660309       Friend GPT  Friend GPT   \n",
       "\n",
       "            recipient_id   recipient_nick recipient_user            timestamp  \\\n",
       "172   360964041130115072  Jason Sheinkopf     chknsquidl  2024-10-02 04:40:36   \n",
       "173   360964041130115072  Jason Sheinkopf     chknsquidl  2024-10-02 04:40:41   \n",
       "174  1286937782299660309       Friend GPT     Friend GPT  2024-10-02 04:41:26   \n",
       "175   360964041130115072  Jason Sheinkopf     chknsquidl  2024-10-02 04:41:32   \n",
       "176   360964041130115072  Jason Sheinkopf     chknsquidl  2024-10-02 04:41:38   \n",
       "\n",
       "                 channel guild  is_dm  ingested  \\\n",
       "172  1287289039245934683            1         0   \n",
       "173  1287289039245934683            1         0   \n",
       "174  1287289039245934683            1         0   \n",
       "175  1287289039245934683            1         0   \n",
       "176  1287289039245934683            1         0   \n",
       "\n",
       "                                               message  \n",
       "172                                           lol yeah  \n",
       "173                                          hey back!  \n",
       "174                                                sup  \n",
       "175                         sup back! everything good?  \n",
       "176  yup! i'm doin alright. just hangin out in this...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "friend_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
